{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf393be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4a74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c)\n",
    "class GaussianNaiveBayesClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.class_probs = {}\n",
    "        self.mean = {}\n",
    "        self.variance = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        unique_classes = np.unique(y)\n",
    "        \n",
    "        for class_label in unique_classes:\n",
    "            class_indices = np.where(y == class_label)\n",
    "            class_data = X[class_indices]\n",
    "            \n",
    "            self.class_probs[class_label] = len(class_data) / len(X)\n",
    "            self.mean[class_label] = np.mean(class_data, axis=0)\n",
    "            self.variance[class_label] = np.var(class_data, axis=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        \n",
    "        for sample in X:\n",
    "            class_scores = {}\n",
    "            \n",
    "            for class_label in self.class_probs:\n",
    "                class_prob = np.log(self.class_probs[class_label])\n",
    "                class_scores[class_label] = class_prob + np.sum(np.log(norm.pdf(sample, self.mean[class_label], np.sqrt(self.variance[class_label]+1e-9))))\n",
    "            \n",
    "            predicted_class = max(class_scores, key=class_scores.get)\n",
    "            predictions.append(predicted_class)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.predict(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec16f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d)\n",
    "full_data = pd.read_csv('banking.csv')\n",
    "train_set, test_set = train_test_split(full_data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = train_set.drop(\"y\", axis=1) # drop labels for training set\n",
    "train_labels = train_set[\"y\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1ace59",
   "metadata": {},
   "source": [
    "#### For the categorical columns, we need to stratify them to one-hot data so that our program can read these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d4fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (e)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "    \n",
    "    \n",
    "# let's now combine the numerical and categorical pipelines\n",
    "num_attribs = ['age','duration','campaign','pdays','previous','emp_var_rate','cons_price_idx',\n",
    "               'cons_conf_idx','euribor3m','nr_employed']\n",
    "cat_attribs = ['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(sparse=False)),\n",
    "    ])\n",
    "\n",
    "# and concatenate them with FeatureUnion class\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])\n",
    "\n",
    "# this is the final transformation result!\n",
    "train_prepared = full_pipeline.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06807ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes:  0.8148822529740228\n"
     ]
    }
   ],
   "source": [
    "# (f)\n",
    "# Naive Bayes\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", full_pipeline),\n",
    "        (\"NB\", GaussianNaiveBayesClassifier())\n",
    "    ])\n",
    "# A full pipeline with both preparation and prediction\n",
    "full_pipeline_with_predictor.fit(train_data, train_labels)\n",
    "\n",
    "test_data = test_set.drop(\"y\", axis=1) # drop labels for training set\n",
    "test_labels = test_set[\"y\"].copy()\n",
    "print('Accuracy of Naive Bayes: ', full_pipeline_with_predictor.score(test_data,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161d76fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LDA:  0.9051954357853847\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "full_pipeline_with_predictor2 = Pipeline([\n",
    "        (\"preparation\", full_pipeline),\n",
    "        ('classifier', LinearDiscriminantAnalysis())\n",
    "    ])\n",
    "\n",
    "full_pipeline_with_predictor2.fit(train_data, train_labels)\n",
    "print('Accuracy of LDA: ', full_pipeline_with_predictor2.score(test_data,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83cc6176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000866</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>-0.034369</td>\n",
       "      <td>0.024365</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.129372</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>-0.017725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>-0.000866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.071699</td>\n",
       "      <td>-0.047577</td>\n",
       "      <td>0.020640</td>\n",
       "      <td>-0.027968</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>-0.008173</td>\n",
       "      <td>-0.032897</td>\n",
       "      <td>-0.044703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>0.004594</td>\n",
       "      <td>-0.071699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052584</td>\n",
       "      <td>-0.079141</td>\n",
       "      <td>0.150754</td>\n",
       "      <td>0.127836</td>\n",
       "      <td>-0.013733</td>\n",
       "      <td>0.135133</td>\n",
       "      <td>0.144095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pdays</th>\n",
       "      <td>-0.034369</td>\n",
       "      <td>-0.047577</td>\n",
       "      <td>0.052584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.587514</td>\n",
       "      <td>0.271004</td>\n",
       "      <td>0.078889</td>\n",
       "      <td>-0.091342</td>\n",
       "      <td>0.296899</td>\n",
       "      <td>0.372605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous</th>\n",
       "      <td>0.024365</td>\n",
       "      <td>0.020640</td>\n",
       "      <td>-0.079141</td>\n",
       "      <td>-0.587514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.420489</td>\n",
       "      <td>-0.203130</td>\n",
       "      <td>-0.050936</td>\n",
       "      <td>-0.454494</td>\n",
       "      <td>-0.501333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp_var_rate</th>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.027968</td>\n",
       "      <td>0.150754</td>\n",
       "      <td>0.271004</td>\n",
       "      <td>-0.420489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.775334</td>\n",
       "      <td>0.196041</td>\n",
       "      <td>0.972245</td>\n",
       "      <td>0.906970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cons_price_idx</th>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>0.127836</td>\n",
       "      <td>0.078889</td>\n",
       "      <td>-0.203130</td>\n",
       "      <td>0.775334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058986</td>\n",
       "      <td>0.688230</td>\n",
       "      <td>0.522034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <td>0.129372</td>\n",
       "      <td>-0.008173</td>\n",
       "      <td>-0.013733</td>\n",
       "      <td>-0.091342</td>\n",
       "      <td>-0.050936</td>\n",
       "      <td>0.196041</td>\n",
       "      <td>0.058986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.277686</td>\n",
       "      <td>0.100513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euribor3m</th>\n",
       "      <td>0.010767</td>\n",
       "      <td>-0.032897</td>\n",
       "      <td>0.135133</td>\n",
       "      <td>0.296899</td>\n",
       "      <td>-0.454494</td>\n",
       "      <td>0.972245</td>\n",
       "      <td>0.688230</td>\n",
       "      <td>0.277686</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nr_employed</th>\n",
       "      <td>-0.017725</td>\n",
       "      <td>-0.044703</td>\n",
       "      <td>0.144095</td>\n",
       "      <td>0.372605</td>\n",
       "      <td>-0.501333</td>\n",
       "      <td>0.906970</td>\n",
       "      <td>0.522034</td>\n",
       "      <td>0.100513</td>\n",
       "      <td>0.945154</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     age  duration  campaign     pdays  previous  \\\n",
       "age             1.000000 -0.000866  0.004594 -0.034369  0.024365   \n",
       "duration       -0.000866  1.000000 -0.071699 -0.047577  0.020640   \n",
       "campaign        0.004594 -0.071699  1.000000  0.052584 -0.079141   \n",
       "pdays          -0.034369 -0.047577  0.052584  1.000000 -0.587514   \n",
       "previous        0.024365  0.020640 -0.079141 -0.587514  1.000000   \n",
       "emp_var_rate   -0.000371 -0.027968  0.150754  0.271004 -0.420489   \n",
       "cons_price_idx  0.000857  0.005312  0.127836  0.078889 -0.203130   \n",
       "cons_conf_idx   0.129372 -0.008173 -0.013733 -0.091342 -0.050936   \n",
       "euribor3m       0.010767 -0.032897  0.135133  0.296899 -0.454494   \n",
       "nr_employed    -0.017725 -0.044703  0.144095  0.372605 -0.501333   \n",
       "\n",
       "                emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  \\\n",
       "age                -0.000371        0.000857       0.129372   0.010767   \n",
       "duration           -0.027968        0.005312      -0.008173  -0.032897   \n",
       "campaign            0.150754        0.127836      -0.013733   0.135133   \n",
       "pdays               0.271004        0.078889      -0.091342   0.296899   \n",
       "previous           -0.420489       -0.203130      -0.050936  -0.454494   \n",
       "emp_var_rate        1.000000        0.775334       0.196041   0.972245   \n",
       "cons_price_idx      0.775334        1.000000       0.058986   0.688230   \n",
       "cons_conf_idx       0.196041        0.058986       1.000000   0.277686   \n",
       "euribor3m           0.972245        0.688230       0.277686   1.000000   \n",
       "nr_employed         0.906970        0.522034       0.100513   0.945154   \n",
       "\n",
       "                nr_employed  \n",
       "age               -0.017725  \n",
       "duration          -0.044703  \n",
       "campaign           0.144095  \n",
       "pdays              0.372605  \n",
       "previous          -0.501333  \n",
       "emp_var_rate       0.906970  \n",
       "cons_price_idx     0.522034  \n",
       "cons_conf_idx      0.100513  \n",
       "euribor3m          0.945154  \n",
       "nr_employed        1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (g)\n",
    "numerical_data = full_data[num_attribs]\n",
    "numerical_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34643077",
   "metadata": {},
   "source": [
    "#### We can see that many variables are highly correlated with each other, which violates the assumption of Naive Bayes Classifier. Therefore, here LDA has better performance than Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f45e393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
