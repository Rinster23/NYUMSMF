{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Numerical Methods for PDE II\n",
    "\n",
    "## Topics\n",
    "\n",
    "* I. Stability of FDM for Black-Scholes\n",
    "* II. FDM scheme smoothing technique\n",
    "* III. Nonlinear PDEs in Finance and Optimal Execution\n",
    "* IV. 2D-PDE and the ADI method\n",
    "* Other Topics (in class)\n",
    "\n",
    "$\\renewcommand{fD}{\\mathfrak{D}}$\n",
    "$\\newcommand{\\a}{\\alpha}$ $\\newcommand{\\s}{\\sigma}$ $\\newcommand{\\half}{\\frac{1}{2}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistence and Stability of FDM\n",
    "\n",
    "Let's consider $D$ a differential operator. In finance, usually $D = \\partial_t + \\mathcal L$ where $\\mathcal L$ is a second order differential operator.\n",
    "\n",
    "Recall the notation that we try to approximate $u(x,t)$ on a grid $t_0 = 0 < t_1 < ... < t_M = T$ and $x_{min} = x_0 < x_1 < ... < x_N = x_{max}$. For simplicity of notation we consider a uniform grid $t_{k+1} - t_k = \\Delta t$ and $x_{n+1} - x_n = \\Delta_x$.\n",
    "\n",
    "Let's consider a discretized (finite difference) scheme $D_{nk}$ of $D$. \n",
    "\n",
    "The (local) truncation error is given by $T_{nk} = D_{nk}u - D(u)(t_k, x_n)$ where $u$ is a smooth enough function. If $u$ is a solution to $Du = 0$ then $T_{nk} = D_{nk}u$.\n",
    "\n",
    "A scheme is **consistent** if $T_{nk}u \\to 0$ as $(\\Delta_x, \\Delta_t) \\to 0$ for any smooth function $u$.\n",
    "\n",
    "**Remark:** consistency is often optimed by design in FDM scheme as a result of Taylor expansions.\n",
    "\n",
    "A scheme **converges** if the solution to the (finite difference) scheme $\\tilde u_{nk} = u_{nk}$ satisfies $\\sup_{nk} || u_{nk} - u(x_n, t_k))|| \\to 0$ as $(\\Delta_x, \\Delta_t) \\to 0$ where $u$ is the solution to $Du = 0$.\n",
    "\n",
    "A scheme is **stable** if its solution $u_{nk}$ satisfies $|| u_{n .} ||^2 \\leq C_T \\sum_{l=0}^{n_0} || u_{l .} ||^2$ for all $T>0$ and some $C_T$ and $n_0 \\in \\mathbb N$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Lax Equivalence Theorem** states that if there exists a well-posed solution to $Du$ and then a consistent finite difference scheme is convergent is and only if it is stable.\n",
    "\n",
    "This results leads to (essentially) consider analyzing the stability of a scheme when considering a potential finite difference scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Von Neuman Analysis\n",
    "\n",
    "The *formal* analysis below relies on Fourier Aanlysis.\n",
    "\n",
    "Let $u_{nk}$ be a discrete function defined on a grid and let's consider its Fourier series for $z \\in \\left [- \\frac{\\pi}{\\Delta_x}, \\frac{\\pi}{\\Delta_x} \\right]$\n",
    "$$ \\hat u_k(z) = \\frac{\\Delta_x}{\\sqrt{2 \\pi}} \\sum_{n \\in \\mathbb Z} u_{nk} e^{in \\Delta_x z} $$\n",
    "\n",
    "The formula for the coefficients of a trigonometric series (discrete Fourier inversion formula) yields\n",
    "$$ u_{nk} = \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\frac{\\pi}{\\Delta_x}}^{\\frac{\\pi}{\\Delta_x}} e^{i n \\Delta_x z} \\hat u_k(z)dz $$\n",
    "\n",
    "Let's consider that the FD scheme has the form\n",
    "$$ u_{n,k+1} = \\sum_{j=-L}^H w_j u_{n+j,k} $$\n",
    "\n",
    "for some weights $w_j = w_j(\\Delta_x, \\Delta_t)$. Then\n",
    "\n",
    "\\begin{split}\n",
    "\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\frac{\\pi}{\\Delta_x}}^{\\frac{\\pi}{\\Delta_x}} e^{i n \\Delta_x z} \\hat u_{k+1}(z)dz & = u_{n, k+1} \\\\\n",
    "& = \\sum_{j=-L}^H w_j u_{n+j,k} \\\\\n",
    "& = \\sum_{j=-L}^H w_j \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\frac{\\pi}{\\Delta_x}}^{\\frac{\\pi}{\\Delta_x}} e^{i (n+j) \\Delta_x z} \\hat u_k(z)dz\\\\\n",
    "& = \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\frac{\\pi}{\\Delta_x}}^{\\frac{\\pi}{\\Delta_x}} e^{i n \\Delta_x z} \\sum_{j=-L}^H w_j  e^{i j \\Delta_x z} \\hat u_k(z)dz\n",
    "\\end{split}\n",
    "\n",
    "By unicity of the coefficients, we get\n",
    "$$ \\hat u_{k+1}(z) = \\left( \\sum_{j=-L}^H w_j  e^{i j \\Delta_x z} \\right) \\hat u_k(z) $$\n",
    "\n",
    "The function $\\zeta(z, \\Delta_x, \\Delta_t) = \\zeta(z) = \\sum_{j=-L}^H w_j  e^{i j \\Delta_x z}$ is called the **amplification** factor as by induction, one gets\n",
    "$$ \\hat u_k(z) = \\zeta(z)^k \\hat u_0(z) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The useful results in practice is that a FD scheme is stable if there exists a constant $C$ that does not depend on $(z, \\Delta_x, \\Delta_t)$ such that $|\\zeta(z)| \\leq 1 + C \\delta_t$ for all $\\Delta_x < \\delta_x$ and $\\Delta_t < \\delta_t$. When $\\zeta(z)$ does not depends on $\\Delta_t$, the condition $|\\zeta(z)| \\leq 1$ is sufficient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples on Various Schemes\n",
    "\n",
    "### Explicit Type\n",
    "For a scheme of the form\n",
    "$$ u_{n,k+1} = au_{n-1,k} + b u_{n,k} + c u_{n+1,k} $$\n",
    "\n",
    "Then\n",
    "$$ \\zeta(z) = a e^{i(-1) \\Delta_x z} + b + c e^{i \\Delta_x z} $$\n",
    "\n",
    "In the instance of the heat equation, we have for $\\gamma = \\sigma^2 \\Delta_t / (2 \\Delta_x^2)$\n",
    "$$ u_{n,k+1} = u_{n,k} + \\gamma(u_{n-1,k} - 2 u_{n,k} + u_{n+1,k}) $$\n",
    "\n",
    "leading to\n",
    "$$ \\zeta(z) = 1 - 2\\gamma(1-\\cos(\\Delta_x z)) $$\n",
    "\n",
    "This gives that $\\gamma \\leq \\frac{1}{2} \\Rightarrow |\\zeta(z)| \\leq 1$\n",
    "\n",
    "\n",
    "### Implicit Type\n",
    "For a scheme of the form\n",
    "$$ u_{n,k} = u_{n,k-1} + au_{n-1,k} + b u_{n,k} + c u_{n+1,k} $$\n",
    "\n",
    "Then\n",
    "$$ \\zeta(z) = \\left(1 - a e^{i(-1) \\Delta_x z} + b + c e^{i \\Delta_x z}\\right)^{-1} $$\n",
    "\n",
    "In the instance of the heat equation\n",
    "$$ u_{n,k} = u_{n,k-1} + \\gamma(u_{n-1,k} -2 u_{n,k} + u_{n+1,k}) $$\n",
    "\n",
    "Then\n",
    "$$ \\zeta(z) = \\left(1 -  \\gamma \\left(e^{i(-1) \\Delta_x z} - 2 +  e^{i \\Delta_x z}\\right) \\right)^{-1} $$\n",
    "\n",
    "so that one always have $|\\zeta(z)| \\leq 1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Instance of FDM for Black-Scholes:\n",
    "\n",
    "When $r \\neq 0$ for the Black-Scholes equation:\n",
    "$$\n",
    "\\zeta(z)  = 1 - r\\triangle t + \\sigma^2 x_j^2 \\frac{\\triangle t}{\\triangle x^2} \\cdot 2\\sin^2(\\Delta_x z) + i\\; r x_j \\frac{\\triangle t}{\\triangle x} \\sin(\\Delta_x z)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* To satisfy $ |\\zeta(z)| < 1 $, we require\n",
    "\n",
    "\\begin{aligned}\n",
    "\\renewcommand{PDut}{\\frac{\\partial u}{\\partial t}}\n",
    "\\renewcommand{PDux}{\\frac{\\partial u}{\\partial x}}\n",
    "\\renewcommand{PDutt}{\\frac{\\partial ^2u}{\\partial t^2}}\n",
    "\\renewcommand{PDuxx}{\\frac{\\partial ^2u}{\\partial x^2}}\n",
    "\\renewcommand{FDut}{\\frac{u_{i,k+1}-u_{i,k}}{\\triangle t}}\n",
    "\\renewcommand{FDutb}{\\frac{u_{i,k}-u_{i,k-1}}{\\triangle t}}\n",
    "\\renewcommand{FDutc}{\\frac{u_{i,k+1}-u_{i,k-1}}{2\\triangle t}}\n",
    "\\renewcommand{FDutt}{\\frac{u_{i,k+1}-2u_{i,k}+u_{i,k-1}}{\\triangle t^2}}\n",
    "\\renewcommand{FDux}{\\frac{u_{i+1,k}-u_{i,k}}{\\triangle x}}\n",
    "\\renewcommand{FDuxb}{\\frac{u_{i,k}-u_{i-1,k}}{\\triangle x}}\n",
    "\\renewcommand{FDuxc}{\\frac{u_{i+1,k}-u_{i-1,k}}{2\\triangle x}}\n",
    "\\renewcommand{FDuxx}{\\frac{u_{i+1,k}-2u_{i,k}+u_{i-1,k}}{\\triangle x^2}}\n",
    "& r >0,\n",
    "\\\\\n",
    "& \\triangle t < \\frac{\\triangle x^2}{ \\sigma^2 x_{max}^2 },\n",
    "\\\\\n",
    "& \\triangle t < \\frac{ \\sigma^2 }{r^2 }.\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "* The first condition is not always standard anymore nowadays, but still okay in most cases/\n",
    "\n",
    "* The last condition does not have much impact in practice unless the volatility is very small.\n",
    "\n",
    "* So the important one is the second condition, which was indicated in the last lecture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Scheme Smoothing\n",
    "\n",
    "The Crank-Nicholson scheme is not perfect and depending on the volatility level, can give rise to spurious oscilatory behavior or the strike or barrier levels.\n",
    "\n",
    "The idea is to find approximations of the form\n",
    "$$ \\frac{a u(x+\\Delta_x) + b u(x) + cu(x-\\Delta)}{\\Delta_x^2} = u''(x) + O(\\Delta_x^2) $$\n",
    "\n",
    "The general idea is to consider a basis of function $B = (\\phi_1(x), \\phi_2(x), \\phi_3(x))$, then for a given $x_n$, we have:\n",
    "\n",
    "\\begin{split}\n",
    "\\frac{a \\phi_1(x_0+\\Delta_x) + b \\phi_1(x_0) + c\\phi_1(x_0-\\Delta_x)}{\\Delta_x^2} &= \\phi_1''(x_0)\\\\\n",
    "\\frac{a \\phi_2(x_0+\\Delta_x) + b \\phi_2(x_0) + c\\phi_2(x_0-\\Delta_x)}{\\Delta_x^2} &= \\phi_2''(x_0)\\\\\n",
    "\\frac{a \\phi_3(x_0+\\Delta_x) + b \\phi_3(x_0) + c\\phi_3(x_0-\\Delta_x)}{\\Delta_x^2} &= \\phi_3''(x_0)\n",
    "\\end{split}\n",
    "\n",
    "In general, $(a,b,c)$ would depend on $x_0$, but in the case of some special choices, that is not the case.\n",
    "\n",
    "The Exponatially fitted scheme corresponds to $B = (1, e^{\\lambda x}, e^{-\\lambda x})$  and leads to:\n",
    "\n",
    "\\begin{split}\n",
    "\\frac{a  + b  + c}{\\Delta_x^2} &= 0\\\\\n",
    "\\frac{a e^{\\lambda \\Delta_x} + b  + c e^{-\\lambda \\Delta_x}}{\\Delta_x^2} &= \\lambda^2\\\\\n",
    "\\frac{a e^{-\\lambda \\Delta_x} + b  + c e^{\\lambda \\Delta_x}}{\\Delta_x^2} &= \\lambda^2\n",
    "\\end{split}\n",
    "\n",
    "whose solution is\n",
    "$$ (a,b,c) = \\Delta_x^2 \\frac{\\lambda^2 e^{\\lambda \\Delta_x}}{(e^{\\lambda \\Delta_x}-1)^2} \\left(1 , -2 , 1 \\right) $$\n",
    "\n",
    "Note that $(a,b,c) \\to (1,-2,1)$ as $\\lambda \\to 0$.\n",
    "\n",
    "Many choices of base are possible $(1, e^{\\lambda_1 x}, e^{\\lambda_2 x})$, $(1, \\sin(\\lambda_1 x), \\cos(\\lambda_2 x))$ being the most commons with $\\lambda_1 = \\lambda_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other smoothing techniques\n",
    "\n",
    "* Having a first few implicit steps first, then switching to CN\n",
    "* Adding more points in space around singularities (in the payoff, i.e. discountinuities, or in it's derivatives, e.g. strike)\n",
    "* Adding more points in time around early exercise dates (e.g. for Bermudan options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Nonlinear PDEs in Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Optimization and Hamilton-Jacobi-Bellman PDE\n",
    "\n",
    "Let us consider a controlled Markovian process, namely something of the form\n",
    "$$ dX_t = \\mu(t,X_t, \\a_t) dt + \\s(t,X_t, \\a_t) dW_t $$\n",
    "\n",
    "where $\\a_t$ is the control process. The presentation is done under in a 1-dimensional case, but generalizing is just a matter of notation. Note that most of the time, the control process is Markovian: it has the form $\\a_t = \\a(t,X_t)$ and $f$ is chosen so as to maximize some (stochatic) optimization problem.\n",
    "\n",
    "For a given (adpated) process $(\\a_u)_{t\\leq u \\leq T}$, one defines:\n",
    "$$ J(t,x,(\\a_u)_{t\\leq u \\leq T}) = E\\left( g(X_T) + \\int_t^T f(u, X_u, \\a_u) du \\;\\Big|  X_t = x\\right) $$\n",
    "\n",
    "and then the objective is to solve\n",
    "$$ J(t,x) = \\sup_{(\\a_u)_{t\\leq u \\leq T} \\in \\mathcal A(t,T)} J(t,x,(\\a_u)_{t\\leq u \\leq T}) $$\n",
    "\n",
    "where $\\mathcal A(t,T)$ is the set of (adapted) process $u \\to \\a_u$ for $u \\in [t,T]$ and taking values in $\\mathcal A \\subset \\mathbb R$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark on notation:** \n",
    "* $J(t,x)$ is the optimal function is often noted $J^*(t,x)$ while we simply removed the dependence in the controled process.\n",
    "* The process $X_u$ for $t \\leq u$ is often noted $X_u^{t,x, \\alpha}$ to indicate it depends on $\\alpha$ and that $X_t = x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamilton-Jacobi-Bellman PDE\n",
    "\n",
    "It is clear that $$ J(T,x) = g(x) $$.\n",
    "\n",
    "A generalisation of Feyman-Kac theorem is then (under the proper regularity assumptions)\n",
    "\n",
    "$$ \\partial_t J + \\sup_{a \\in \\mathcal A} \\{ \\mu(t,x,a) \\partial_x J + \\half \\s^2(t,x,a) \\partial^2_{xx} J + f(t,x,a) \\} = 0 $$\n",
    "\n",
    "Note that the value $a^*$ which achieve the supremum is a function of the form $a^* = a^*(t,x)$, and the optimal control process is given by:\n",
    "$ \\alpha^*_t = a^*(t,X_t)$\n",
    "\n",
    "The HJB PDE is nonlinear because\n",
    "$$ F(t,x, \\partial_x J, \\partial^2_{xx}J) = \\sup_{a \\in \\mathcal A} \\{ \\mu(t,x,a) \\partial_x J + \\half \\s^2(t,x,a) \\partial^2_{xx} J + f(t,x,a) \\} $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Execution PDE\n",
    "\n",
    "Consider the traded quantity to be $d\\Delta_t = q_t dt$ where $q_t dt$ is the \"number of stock traded\" at time $t$ over a period of time $dt$.\n",
    "\n",
    "We consider the effect of permanent price impact, namely the stock price is affected by the rate of trading\n",
    "$$ dS_t = S_t (g(q_t) dt + \\sigma dW_t) $$\n",
    "\n",
    "as well a temporary impact when the agent execute the trade\n",
    "$$ \\tilde S_t = S_t +  f(q_t) $$\n",
    "\n",
    "where $f$ contains the bid-ask spread.\n",
    "\n",
    "We consider the problem of buying at quantity of $Q$ shares by time $T$ starting with $\\Delta_0 = 0$.\n",
    "\n",
    "The agent want to minimize its cost, namely solve for \n",
    "$$ J(t,s, \\Delta) = \\inf_{q \\in \\mathcal A} E_t\\left( \\int_t^T \\tilde S_u q_u du + (Q-\\Delta_T)S_T + \\lambda(Q-\\Delta_T)^2 \\right) $$\n",
    "\n",
    "where\n",
    "* $\\int_t^T \\tilde S_u q_u du$ is the running execution cost\n",
    "* $(Q-\\Delta_T)S_T$ is the terminical execution cost at mid price\n",
    "* $(Q-\\Delta_T)^2$ is a terminal penalty for not acquiring all the shares before $T$. We see that as such $\\lambda$ has a direct effect on the trading speed.\n",
    "\n",
    "\n",
    "This gives rise to a nonlinear HJB equation of the form\n",
    "\\begin{split}\n",
    "J(T,s, \\Delta) &= (Q-\\Delta) s + \\lambda (Q-\\Delta)^2\\\\\n",
    "0 &= \\partial_t J + \\frac{1}{2} s^2 \\sigma^2 \\partial^2_{ss} J + \\inf_{q \\in A} \\left( (S+f(q))q + s g(q) \\partial_s J + q \\partial_{\\Delta} J \\right)\n",
    "\\end{split}\n",
    "\n",
    "where $A$ represents the set of trading constraints (e.g. $ q \\geq 0$ indicating that the agent cannot sell shares).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical strategies to solve nonlinear PDE\n",
    "\n",
    "\n",
    "**Iterative Solving at each time step**\n",
    "It is crucial to note that once one has \"solved\" for \n",
    "$$ \\sup_{a \\in \\mathcal A} \\{ \\mu(t,x,a) \\partial_x J + \\half \\s^2(t,x,a) \\partial^2_{xx} J + f(t,x,a) \\}$$ \n",
    "\n",
    "the solution $a^*(t,x)$ is \"just\" a function of $(t,x)$ and\n",
    "$$ \\mu(t,x,a^*(t,x)) \\partial_x J + \\half \\s^2(t,x,a^*(t,x)) \\partial^2_{xx} J + f(t,x,a^*(t,x)) $$\n",
    "\n",
    "is \"linear\" with respect to $\\partial_x J$ and $\\partial_{xx}^2 J$. So one can solve numerical for $a^*$ at each discretized time step and combined with a PDE scheme (explicit, implicit, CN, etc.)\n",
    "\n",
    "\n",
    "**Fixed-point method**\n",
    "As explained earlier, the function $a^*(t,x)$ can be (also) expressed as a function of the partial derivatives of $J$, namely\n",
    "\n",
    "$$a^*(t,x) = F(t,x,\\partial_x J(t,x), \\partial_{xx}^2 J(t,x)) $$\n",
    "\n",
    "It is sometimes the case that $F$ is known analytically, which often leads to a very nonlinear PDE. The fixed point methods consists in choosing a first estimate of $a_0(t,x)$ and solve using a standard linear PDE solver for:\n",
    "$$ \\partial_t J_0 + \\mu(t,x,a_0) \\partial_x J_0 + \\half \\s^2(t,x,a_0) \\partial^2_{xx} J_0 + f(t,x,a_0) \\} = 0  $$\n",
    "\n",
    "Then the (sub-optimal) control process is updated with\n",
    "$$ a_1(t,x) = F(t,x,\\partial_x J_0(t,x), \\partial_{xx}^2 J_0(t,x)) $$\n",
    "\n",
    "and the procedure is repeated:\n",
    "* solve for the correponding $J_1$ using a linear PDE solver\n",
    "* get $a_2(t,x) = F(t,x,\\partial_x J_1(t,x), \\partial_{xx}^2 J_1(t,x))$\n",
    "* repeat to get $a_{n+1}(t,x) = F(t,x,\\partial_x J_n(t,x), \\partial_{xx}^2 J_n(t,x))$\n",
    "* check that $|a_{n+1} - a_n|_{\\infty} < \\varepsilon$ for a given tolerance threshold.\n",
    "\n",
    "\n",
    "**Monte Carlo Simulations**\n",
    "\n",
    "Simulate a Backward Stochastic Differential Equation (BSDEs) which reuse similar regression techniques to American MC.\n",
    "\n",
    "\n",
    "**Neural Networks**\n",
    "\n",
    "Two choices:\n",
    "* write $J(t,x) = N(t,x,w)$ and solve for $w$ (the weights of the neural network) such that $N$ satisfies the PDE differential operator on the PDE domain and fit the boundary conditions.\n",
    "\n",
    "* write $a^*(t,x) = N(t,x,w)$ and combine solving for $w$ eiher with a linear PDE solver similar to the fixed-point method or by a global optimization on the (discretized) numerical scheme.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# IV. 2D-PDE\n",
    "\n",
    "\n",
    "* Most numerical methods, FDM included, suffer the \"dimentionality\" curse, i.e. the size, complexity of the problem grow exponentially with the dimension.\n",
    "\n",
    "\n",
    "* Usually, Monte Carlo method is the only practical option in dimension $\\geq 3$.\n",
    "\n",
    "\n",
    "* But for two dimensional problems, it is worthwhile to explore the FDM further.\n",
    "\n",
    "\n",
    "* Finance examples that you will need many spatial variables: stochastic vol model, convertible bonds, credit risky bonds, variable annuities, basket option, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: Heston Stochastic Volatility Model\n",
    "\n",
    "\\begin{aligned}\n",
    "& dS_t = rS_t dt + \\sqrt{\\nu_t}S_t dW_t^1\n",
    "\\\\\n",
    "& d\\nu_t = \\kappa(\\theta - \\nu_t) + \\xi\\sqrt{\\nu_t}  dW_t^2\n",
    "\\\\\n",
    "& \\hspace{0.2in} \\left< dW_t^1, dW_t^2 \\right> = \\rho dt\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### PDE for Heston Stochastic Vol Model:\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "\\renewcommand{PDuS}{\\frac{\\partial u}{\\partial S}}\n",
    "\\renewcommand{PDuSS}{\\frac{\\partial ^2u}{\\partial S^2}}\n",
    "\\PDut &+ rS\\PDuS+ (\\kappa(\\theta - \\nu)-\\lambda \\nu )\\frac{\\partial u}{\\partial \\nu} \n",
    "\\\\\n",
    "& + \\frac{1}{2}\\nu S^2\\PDuSS + \\rho\\xi\\nu S\\frac{\\partial^2 u}{\\partial S\\partial \\nu} + \\frac{1}{2}\\xi^2\\nu\\frac{\\partial^2 u}{\\partial \\nu^2} - ru = 0\n",
    "\\end{aligned}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Alternating Direction Implicit Method\n",
    "\n",
    "* Write the Crank-Nicolson method as\n",
    "\n",
    "\\begin{aligned}\n",
    "\\small\n",
    "\\FDut  = & \\frac{1}{4}  \\sigma^2 x_i^2 \\left\\{ \\FDuxx + \\frac{u_{i+1,k+1}-2u_{i,k+1}+u_{i-1,k+1}}{\\triangle x^2} \\right\\}\n",
    "\\\\ \n",
    "    & + \\frac{1}{2} r x_i \\left\\{ \\FDuxc + \\frac{u_{i+1,k+1}-u_{i-1,k+1}}{2\\triangle x} \\right\\} \n",
    "\\\\\n",
    "    & - \\frac{1}{2} r \\left\\{  u_{i,k} +  u_{i,k+1} \\right\\} \n",
    "\\\\\n",
    "    = & - \\frac{1}{2} \\mathfrak{D}\\cdot (  u_{i,k} +  u_{i,k+1} )\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "where $ \\mathfrak{D}\\cdot  u_{i,k} $ can be considered as the Crank-Nicolson finite difference operator on $u_{i,k}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Crank-Nicolson in operator format\n",
    "\n",
    "\n",
    "* The Crank-Nicolson scheme can be denoted as\n",
    "\n",
    "$$\n",
    "(1 + \\frac{1}{2}\\triangle t\\fD)\\cdot u_{i,k+1} = (1 - \\frac{1}{2}\\triangle t\\fD)\\cdot u_{i,k}\n",
    "$$\n",
    "\n",
    "* This is also applicable when the spatial variable $x_i$ is a vector.\n",
    "\n",
    "* For the one spatial variable case, the operator $\\fD$ involves three points in one time slice.\n",
    "\n",
    "* For two dimension case (the Heston model above), the operator will involve five points in one time slice.\n",
    "\n",
    "* So instead of solving a tridiagonal system, now the linear system has five nonzero diagonals, which is much more costly  to solve.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Operator split \n",
    "\n",
    "* The essential idea is that $\\fD = \\fD_1 + \\fD_2$ where $\\partial_t u + \\fD_i u = 0$ can be solved efficiently (e.g. just like in the 1-D case)\n",
    "\n",
    "* The canonical example is $\\fD = \\partial_{xx} + \\partial_{yy}$\n",
    "\n",
    "* For a general second order linear PDE of the for\n",
    "$$ \\fD = a(x) \\partial_x + \\alpha(y) \\partial_y +  \\frac{1}{2} b^2(x,y) \\partial_{xx} + \\frac{1}{2} \\beta^2(x,y) \\partial_{yy} + \\rho b(x,y) \\beta(x,y) \\partial_{x,y} $$\n",
    "\n",
    "  standard change of variables reduces this operator to the case where $\\rho = 0$ (see references).\n",
    "\n",
    "* From $(1\\pm x)(1 \\pm y) = 1 \\pm x \\pm y + xy$ the scheme \n",
    "$$\n",
    "(1 + \\frac{1}{2}\\Delta t(\\fD_1 + \\fD_2))\\cdot u_{i,k+1} = (1 - \\frac{1}{2}\\Delta t(\\fD_1 + \\fD_2))\\cdot u_{i,k}\n",
    "$$\n",
    "\n",
    "and \n",
    "$$\n",
    "(1 + \\frac{1}{2}\\Delta t\\fD_1)(1 + \\frac{1}{2}\\Delta t\\fD_2)\\cdot u_{i,k+1} = (1 - \\frac{1}{2}\\Delta t\\fD_1)(1 - \\frac{1}{2}\\Delta t\\fD_2)\\cdot u_{i,k}\n",
    "$$\n",
    "\n",
    "will have the same consistency. This technique leads to consider the two-step approach of solving\n",
    "\\begin{split}\n",
    "(1 + \\frac{1}{2}\\Delta t\\fD_1) u_{k+1/2} &= (1 - \\frac{1}{2}\\Delta t\\fD_2)\\cdot u_k\\\\\n",
    "(1 + \\frac{1}{2}\\Delta t\\fD_2)\\cdot u_{i,k+1} &= (1 - \\frac{1}{2}\\Delta t\\fD_1) u_{k+1/2}\n",
    "\\end{split}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For the general $n$ spatial variables case, the way to ease the linear system solving (still can't get rid of the problem of the number of discretization points exploded!) is **splitting** the operator $\\fD = \\fD_1 +...+ \\fD_n$:\n",
    "\n",
    "\\begin{aligned}\n",
    "(1 + \\frac{1}{2}\\Delta t\\fD^1)\\cdot u_{i,k+1/n} &= (1-\\frac{1}{2}\\Delta t\\fD^1)\\cdot u_{i,k}\n",
    "\\\\\n",
    "(1 + \\frac{1}{2}\\Delta t\\fD^2)\\cdot u_{i,k+2/n} &= (1-\\frac{1}{2}\\Delta t\\fD^2)\\cdot u_{i,k+1/n}\n",
    "\\\\\n",
    "\\vdots\n",
    "\\\\\n",
    "(1 + \\frac{1}{2}\\Delta t\\fD^n)\\cdot u_{i,k+1} &= (1-\\frac{1}{2}\\Delta t\\fD^n)\\cdot u_{i,k+(n-1)/n}\n",
    "\\end{aligned}\n",
    "\n",
    "and set\n",
    "\n",
    "$$\n",
    "u_{i+1,k} = \\tilde{u}^n_{i,k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "* Essentially, this says trying to solve the problem in a multistep approach: each step is equivalent to the one dimensional Crank-Nicolson method.\n",
    "\n",
    "\n",
    "* This is  merely the basic form, the strategy can be customized to further improve the efficiency (not all steps are implicit) or accuracy (high order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Other Topics\n",
    "\n",
    "DGM"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
